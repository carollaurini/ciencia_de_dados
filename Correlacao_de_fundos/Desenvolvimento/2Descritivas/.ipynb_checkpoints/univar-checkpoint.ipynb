{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn \n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import feature_selection\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import openpyxl\n",
    "from  matplotlib.colors import LinearSegmentedColormap\n",
    "import seaborn as sns\n",
    "import xlsxwriter\n",
    "from sklearn import feature_selection\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fundo a ser analisado\n",
    "nome_da_base =  'book_pagaya_riverview'#'bookx'\n",
    "col_fundos_input = ['Pagaya Opportunity Fund','Riverview ALF']# ['JPEIGLSP Index','BRL Curncy','CAD Curncy','AUD Curncy']#\n",
    "nome_benchmark = \"IBOXHY Index\"#'DXY Index'#\n",
    "diaria=0\n",
    "tempo = 12 #252\n",
    "const = 0.03\n",
    "df=pd.read_csv('P:\\\\ciencia_de_dados\\\\Correlacao_de_fundos\\\\Desenvolvimento\\\\1DataPrep\\\\base_'+ nome_da_base + '.csv',sep =';',index_col=0,decimal=',')\n",
    "\n",
    "if diaria==1:\n",
    "    df_diaria = pd.read_csv('P:\\\\ciencia_de_dados\\\\Correlacao_de_fundos\\\\Desenvolvimento\\\\1DataPrep\\\\base_'+ nome_benchmark + '.csv',sep =';',index_col=0,decimal=',')\n",
    "    df = pd.concat([df_diaria, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Retorno_Positivo'] = np.where(df.Retorno>=0, 1, 0)\n",
    "df['Retorno_Negativo'] = np.where(df.Retorno<0, 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df.pivot(index=[\"data\",\"Ano\",\"Mes\"], columns=\"Product\", values=\"Retorno_1\")\n",
    "df_sub = df_sub.reset_index()\n",
    "df_sub = df_sub.dropna()\n",
    "#df_sub = df_sub.set_index(\"Ano\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria a df_sub1 para calculo do tracking error \n",
    "def f(x):\n",
    "    print(x.name)\n",
    "    return (x.div(df_sub[nome_benchmark]))#divisao entre o o retorno do fundo com o do benchmark\n",
    "\n",
    "df_sub1 = df_sub.apply(lambda x: f(x) if x.name in col_fundos_input else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([df_sub, df_sub1[col_fundos_input].add_suffix('_spread')], axis=1, join=\"inner\")\n",
    "col_fundos = df_concat.columns[3:]\n",
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Retorno Mensal\n",
    "def function_retorno(df,i,const,col_fundos):\n",
    "\n",
    "    pivot_table = pd.pivot_table(df,index=['Ano'],values=[col_fundos[i]],fill_value=1,aggfunc='prod',columns=['Mes'])#,margins=True,margins_name=\"Year\")\n",
    "    pivot_table=pivot_table.rename(columns={1: 'Jan', 2:\"Feb\",3:\"Mar\", 4:\"Apr\", 5:\"May\", 6:\"Jun\",7:\"Jul\", 8:\"Aug\", 9:\"Sep\", 10:\"Oct\", 11:\"Nov\", 12:\"Dec\"})\n",
    "    \n",
    "    ITD_Matrix = [df[df.Ano <= i_ano][col_fundos[i]].prod() for i_ano in df.Ano.unique()]\n",
    "    YTD_Matrix = [df[df.Ano == i_ano][col_fundos[i]].prod() for i_ano in df.Ano.unique()]\n",
    "    \n",
    "    ITD_df=pd.DataFrame(ITD_Matrix, columns = [col_fundos[i]] ,index=df_concat.Ano.unique())\n",
    "    YTD_df=pd.DataFrame(YTD_Matrix, columns = [col_fundos[i]] ,index=df_concat.Ano.unique())\n",
    "    \n",
    "    ITD_df.columns = pd.MultiIndex.from_product([ITD_df.columns, ['Retorno ITD']])\n",
    "    YTD_df.columns = pd.MultiIndex.from_product([YTD_df.columns, ['Retorno YTD']])\n",
    "    \n",
    "   \n",
    "    \n",
    "    pivot_table = pd.concat([pivot_table,YTD_df,ITD_df],axis=1)\n",
    "    pivot_table = pivot_table-1\n",
    "    \n",
    "    \n",
    "    \n",
    "    # backgroung color mapping\n",
    "    my_cmap=LinearSegmentedColormap.from_list('rg',[\"r\", \"w\", \"g\"], N=256)\n",
    "    pivot_table.index.name=\"Retorno Mensal\"\n",
    "    #pivot_table = pivot_table.style.background_gradient(cmap=my_cmap,vmin = -const,vmax = const)\n",
    "    \n",
    "    return pivot_table.applymap('{:.1%}'.format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_retorno(df_concat,0,const,col_fundos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_number = 0.20\n",
    "percentage = \"{:.2%}\".format(a_number)\n",
    "print(percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def float_formatter(a_number):\n",
    "    return \"{:.1%}\".format(a_number)\n",
    "\n",
    "def vol_anualizada(x,tempo):\n",
    "    z = x.std() * (tempo**(1/2))\n",
    "    return z\n",
    "\n",
    "def retorno_anualizado(x,tempo):\n",
    "    return (x.product()**(tempo/float(x.count())) - 1)\n",
    "\n",
    "def MDD(x):\n",
    "    return min(((x/x.cummax()) - 1))\n",
    "\n",
    "def retorno_total(x):\n",
    "    return (x.prod() - 1)\n",
    "\n",
    "def Meses_Positivos(x): #Gambiarra para nomear sum\n",
    "    return x.sum()\n",
    "\n",
    "def Meses_Negativos(x):\n",
    "    return x.sum()\n",
    "\n",
    "def Periodo(x):\n",
    "    return datetime.datetime.strptime(min(x), '%Y-%m-%d').strftime('%b-%Y')+' a ' + datetime.datetime.strptime(max(x), '%Y-%m-%d').strftime('%b-%Y')\n",
    "\n",
    "\n",
    "df.sort_values(by=[\"Product\",'data'],ascending=False,inplace=True)\n",
    "\n",
    "\n",
    "table = df.groupby('Product').agg({\"Retorno\": ['max','min','mean',lambda y: vol_anualizada(y,12)] ,\"Retorno_Negativo\":Meses_Negativos,\"Retorno_Positivo\": Meses_Positivos,\"Retorno_1\" : [retorno_total, lambda x: retorno_anualizado(x,tempo)]})\n",
    "\n",
    "table.columns = table.columns.droplevel(0)\n",
    "table.columns = [\"Retorno Mensal Máximo\",\"Retorno Mensal Minimo\", \"Média dos Retornos Mensais\",'Volatilidade Anualizada','Meses Negativos','Meses Positivos','Retorno Total','Retorno Anualizado']\n",
    "table[\"Sharpe\"] = (table[\"Retorno Anualizado\"] / table[\"Volatilidade Anualizada\"])\n",
    "\n",
    "#Criando o DrawDown\n",
    "df.sort_values(by=[\"Product\",'data'],ascending=True,inplace=True)\n",
    "table2 = df.groupby('Product').agg({\"FinancialPrice\":MDD}).rename(columns={\"FinancialPrice\":\"Maximo Drawdown\"})\n",
    "\n",
    "x=pd.concat([table,table2],axis=1)\n",
    "\n",
    "#Formantando em %\n",
    "for col_name in ['Retorno Mensal Máximo','Retorno Mensal Minimo','Média dos Retornos Mensais','Volatilidade Anualizada','Retorno Total','Retorno Anualizado','Maximo Drawdown']:\n",
    "    x[col_name] = x[col_name].apply(lambda x: float_formatter(x))\n",
    "\n",
    "\n",
    "df_univar = x.T\n",
    "df_univar.index.name=Periodo(df.data)\n",
    "\n",
    "df_univar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressao_linear(df,nome_do_fundo,nome_benchmark): \n",
    "    df['Retorno'] = df['Retorno']*100\n",
    "    df_fundo = df.loc[df.Product == nome_do_fundo,['data','Retorno']]\n",
    "    df_bench = df.loc[df.Product == nome_benchmark,['data','Retorno']]\n",
    "\n",
    "    df_fundo.index = df_fundo['data']\n",
    "    df_bench.index = df_bench['data']\n",
    "    df_join =pd.merge(df_bench, df_fundo,how='inner',left_index=True, right_index=True).dropna()[['Retorno_x','Retorno_y']]\n",
    "\n",
    "    #Regressao Linear total\n",
    "    x = (df_join['Retorno_x']).values.reshape((-1, 1))\n",
    "    y= (df_join['Retorno_y']).values.reshape((-1, 1))\n",
    "    \n",
    "    regr = sklearn.linear_model.LinearRegression()\n",
    "    regr.fit(x, y)\n",
    "    return regr.coef_[0][0],regr.intercept_[0]\n",
    "\n",
    "k=0\n",
    "v = []\n",
    "for i in col_fundos_input:\n",
    "    v.append(regressao_linear(df,i,nome_benchmark))\n",
    "    \n",
    "df_bivar = pd.DataFrame(v,index=col_fundos_input).rename(columns = {0:'Beta',1:'Alpha'}).T\n",
    "df_bivar\n",
    "\n",
    "#Tracking Error\n",
    "v=[]\n",
    "for i in col_fundos_input:\n",
    "    v.append(np.std(df_sub1[i]))\n",
    "\n",
    "\n",
    "df_bivar.loc['Tracking Error'] = [float_formatter(x) for x in v]\n",
    "df_bivar.index.name = ' '\n",
    "df_bivar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.feature_selection.mutual_info_regression(df_sub[col_fundos_input],df_sub[nome_benchmark])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Porcentualizando para os graficos\n",
    "df_sub.iloc[:,3:] = (df_sub.iloc[:,3:] *100)-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=df_sub.iloc[:,3:],kind=\"reg\",plot_kws={'line_kws':{'color':'red','lw':1},'scatter_kws': {'s': 3}},corner= True)\n",
    "plt.savefig('PairplotRegressaoLin.'+nome_da_base+'.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=df.reset_index(),x = 'Retorno',hue = 'Product',fill=True)\n",
    "plt.savefig('Retorno_density_distribution'+nome_da_base+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_fundos1 =col_fundos_input\n",
    "col_fundos1.append(nome_benchmark)\n",
    "\n",
    "corr = df_sub[col_fundos_input].corr()\n",
    "\n",
    "col_fundos1 =col_fundos_input\n",
    "ax = sns.heatmap(\n",
    "    corr,\n",
    "    annot=True, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");\n",
    "plt.tight_layout()\n",
    "plt.savefig('CorrelationMatrix'+nome_da_base+'.png',dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.sort_values(by=['data'],ascending=True,inplace=True)\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CORRELACAO NO TEMPO\n",
    "\n",
    "def func_corr_bootstrap(df,k,ativo1,ativo2):\n",
    "    n1=12\n",
    "    if k>=48:\n",
    "        n1=40\n",
    "    df_rand = df[0:(12+k)].sample(n = n1)\n",
    "    return scipy.stats.pearsonr(df_rand[ativo1], df_rand[ativo2])[0]\n",
    "\n",
    "def janela_corr(df,ativo1,ativo2):\n",
    "    \n",
    "    coef_12=[]\n",
    "    coef_36=[]\n",
    "    coef_60=[]\n",
    "    coef_b=[]\n",
    "    data=[]\n",
    "    \n",
    "    for k in range(0,len(df[ativo1])-(12)):    \n",
    "        janela=12 #Correlacao Simples lag de 12  Meses passados       \n",
    "        coef_12.append(scipy.stats.pearsonr(df[ativo1][(k+12-janela): (k+12)], df[ativo2][(k+12-janela): (k+12)])[0])\n",
    "        \n",
    "        janela=36 #Correlacao Simples lag de 36  Meses passados     \n",
    "        if janela-12<=k:\n",
    "            coef_36.append(scipy.stats.pearsonr(df[ativo1][(k+12-janela): (k+12)], df[ativo2][(k+12-janela): (k+12)])[0])\n",
    "        else: coef_36.append(np.NaN)\n",
    "\n",
    "        janela=60 #Correlacao Simples lag de 60  Meses passados     \n",
    "        if janela-12<=k:\n",
    "            coef_60.append(scipy.stats.pearsonr(df[ativo1][(k+12-janela): (k+12)], df[ativo2][(k+12-janela): (k+12)])[0])\n",
    "        else: coef_60.append(np.NaN)\n",
    "        \n",
    "\n",
    "        #Correlacao Bootstrap \n",
    "        coef_b.append(np.mean([func_corr_bootstrap(df,k,ativo1,ativo2) for i in range(1000)]))\n",
    "        \n",
    "        \n",
    "        data.append(df['data'].iloc[k+12:k+12+1].values[0]) # Dia Atual comeca em index=12\n",
    "\n",
    "    df_teste = pd.DataFrame(\n",
    "        {'mes':data,\n",
    "         'Correlacao_BoostStrapping': coef_b,\n",
    "         'Correlacao_simples_12_meses': coef_12,  \n",
    "         'Correlacao_simples_36_meses': coef_36,\n",
    "         'Correlacao_simples_60_meses': coef_60\n",
    "        })\n",
    "    return df_teste\n",
    "\n",
    "def fplot(df,i,j):\n",
    "    ax = plt.gca()\n",
    "\n",
    "    df.plot(kind='line',x='mes',y='Correlacao_BoostStrapping',linestyle=':', color='black',linewidth=3 , ax=ax)\n",
    "    df.plot(kind='line',x='mes',y='Correlacao_simples_12_meses', color='red', ax=ax)\n",
    "    df.plot(kind='line',x='mes',y='Correlacao_simples_36_meses', color='blue', ax=ax)\n",
    "    df.plot(kind='line',x='mes',y='Correlacao_simples_60_meses', color='green', ax=ax)\n",
    "\n",
    "    plt.title(str(i)+' x '+str(j))\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.grid() \n",
    "    plt.ylim([-1, 1])\n",
    "    plt.savefig('CorrelacaoTemporal_'+nome_da_base+i+j+'.png',dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "def fplotinterval(df,i,j):\n",
    "    x= [func_corr_bootstrap(df,(len(df)-12),i,j) for k in range(1000)]\n",
    "    confidence_interval = scipy.stats.t.interval(0.95, 999, np.mean(x), np.std(x))\n",
    "\n",
    "    fig = sns.histplot(x)\n",
    "    plt.suptitle(str(i)+' x '+str(j))\n",
    "    plt.title('Correlação Média: '+ str(np.round(np.mean(x),2))+' e IC: (' + str(np.round(confidence_interval[0],2)) +', '+str(np.round(confidence_interval[1],2))+')', fontsize=10, fontweight='bold')\n",
    "\n",
    "    print(np.mean(x),np.std(x),confidence_interval)\n",
    "    plt.savefig('HistogramaCorrelações_'+nome_da_base+i+j+'.png')\n",
    "    plt.show()\n",
    "    \n",
    "#MAIN  \n",
    "for i in range(len(df_sub.columns[3:])):\n",
    "    for j in range(i+1,len(df_sub.columns[3:])): \n",
    "        df_corr = janela_corr(df_sub,df_sub.columns[3:][i],df_sub.columns[3:][j])\n",
    "        fplot(df_corr,df_sub.columns[3:][i],df_sub.columns[3:][j])\n",
    "        fplotinterval(df_sub,df_sub.columns[3:][i],df_sub.columns[3:][j])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Volatilidade no TEMPO\n",
    "\n",
    "def func_vol_bootstrap(df,k,ativo):\n",
    "    n1=12\n",
    "    if k>=48:\n",
    "        n1=40\n",
    "    df_rand = df[0:(12+k)].sample(n = n1)\n",
    "    return vol_anualizada(df_rand[ativo],12)\n",
    "\n",
    "def janela_vol(df,ativo):\n",
    "    \n",
    "    vol_coef_12=[]\n",
    "    vol_coef_36=[]\n",
    "    vol_coef_60=[]\n",
    "    vol_coef_b=[]\n",
    "    vol_data=[]\n",
    "    \n",
    "    for k in range(0,len(df[ativo])-(12)): \n",
    "        \n",
    "        janela=12 #Correlacao Simples lag de 12  Meses passados       \n",
    "        vol_coef_12.append(vol_anualizada(df[ativo][(k+12-janela): (k+12)], 12))\n",
    "        \n",
    "        janela=36 #Correlacao Simples lag de 36  Meses passados     \n",
    "        if janela-12<=k:\n",
    "            vol_coef_36.append(vol_anualizada(df[ativo][(k+12-janela): (k+12)], 12))\n",
    "        else: vol_coef_36.append(np.NaN)\n",
    "\n",
    "        janela=60 #Correlacao Simples lag de 60  Meses passados     \n",
    "        if janela-12<=k:\n",
    "            vol_coef_60.append(vol_anualizada(df[ativo][(k+12-janela): (k+12)], 12))\n",
    "        else: vol_coef_60.append(np.NaN)\n",
    "        \n",
    "\n",
    "        #Correlacao Bootstrap \n",
    "        vol_coef_b.append(np.mean([func_vol_bootstrap(df,k,ativo) for i in range(1000)]))\n",
    "        \n",
    "        \n",
    "        vol_data.append(df['data'].iloc[k+12:k+12+1].values[0]) # Dia Atual comeca em index=12\n",
    "\n",
    "    df_teste = pd.DataFrame(\n",
    "        {'mes':vol_data,\n",
    "         'Volatilidade_BoostStrapping': vol_coef_b,\n",
    "         'Volatilidade_simples_12_meses': vol_coef_12,  \n",
    "         'Volatilidade_simples_36_meses': vol_coef_36,\n",
    "         'Volatilidade_simples_60_meses': vol_coef_60\n",
    "        })\n",
    "    return df_teste\n",
    "\n",
    "def fplot_vol(df,i):\n",
    "    ax = plt.gca()\n",
    "\n",
    "    df.plot(kind='line',x='mes',y='Volatilidade_BoostStrapping',linestyle=':', color='black',linewidth=3 , ax=ax)\n",
    "    df.plot(kind='line',x='mes',y='Volatilidade_simples_12_meses', color='red', ax=ax)\n",
    "    df.plot(kind='line',x='mes',y='Volatilidade_simples_36_meses', color='blue', ax=ax)\n",
    "    df.plot(kind='line',x='mes',y='Volatilidade_simples_60_meses', color='green', ax=ax)\n",
    "\n",
    "    plt.title(str(i))\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.grid() \n",
    "    #plt.ylim([-1, 1])\n",
    "    plt.savefig('VolatilidadeTemporal'+nome_da_base+i+'.png',dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "def fplotinterval_vol(df,i):\n",
    "    x= [func_vol_bootstrap(df,(len(df)-12),i) for k in range(1000)]\n",
    "    confidence_interval = scipy.stats.t.interval(0.95, 999, np.mean(x), np.std(x))\n",
    "\n",
    "    fig = sns.histplot(x)\n",
    "    plt.suptitle(str(i))\n",
    "    plt.title('Volatilidade Média: '+ str(np.round(np.mean(x),2))+' e IC: (' + str(np.round(confidence_interval[0],2)) +', '+str(np.round(confidence_interval[1],2))+')', fontsize=10, fontweight='bold')\n",
    "\n",
    "    print(np.mean(x),np.std(x),confidence_interval)\n",
    "    plt.savefig('HistogramaVolatilidade'+nome_da_base+i+'.png')\n",
    "    plt.show()\n",
    "    \n",
    "#MAIN  \n",
    "for i in range(len(df_sub.columns[3:])): \n",
    "        df_vol = janela_vol(df_sub,df_sub.columns[3:][i])\n",
    "        fplot_vol(df_vol, df_sub.columns[3:][i])\n",
    "        fplotinterval_vol(df_sub,df_sub.columns[3:][i])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.columns[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter(nome_da_base+'.xlsx', engine='xlsxwriter')\n",
    "workbook = writer.book\n",
    "worksheet = workbook.add_worksheet('Sumario')\n",
    "\n",
    "options = {\n",
    "    'width': 256,\n",
    "    'height': 100,\n",
    "    'x_offset': 10,\n",
    "    'y_offset': 10,\n",
    "\n",
    "    'font': {'color': 'white',\n",
    "             'size': 20},\n",
    "    'align': {'vertical': 'middle',\n",
    "              'horizontal': 'center'\n",
    "              },\n",
    "    'gradient': {'colors': ['#3E9EBC',\n",
    "                            '#2F778D',\n",
    "                            ]},\n",
    "}\n",
    "\n",
    "options2 = {\n",
    "    'width': 200,\n",
    "    'height': 20,\n",
    "    'x_offset': 10,\n",
    "    'y_offset': 10,\n",
    "\n",
    "    'font': {'color': 'white',\n",
    "             'size': 10},\n",
    "    'align': {'vertical': 'middle',\n",
    "              'horizontal': 'center'\n",
    "              },\n",
    "    'gradient': {'colors': ['#800000',\n",
    "                            '#800000',\n",
    "                            ]},\n",
    "}\n",
    "options3 = {\n",
    "    'width': 200,\n",
    "    'height': 20,\n",
    "    'x_offset': 10,\n",
    "    'y_offset': 10,\n",
    "\n",
    "    'font': {'color': 'white',\n",
    "             'size': 10},\n",
    "    'align': {'vertical': 'middle',\n",
    "              'horizontal': 'center'\n",
    "              },\n",
    "    'gradient': {'colors': ['#3E9EBC',\n",
    "                            '#2F778D',\n",
    "                            ]},\n",
    "}\n",
    "worksheet.insert_textbox('B2', 'Sumário Estatístico',options)\n",
    "\n",
    "\n",
    "writer.sheets['Sumario'] = worksheet\n",
    "spread_names = [s for s in df_concat.columns[3:] if 'spread' in s]\n",
    "\n",
    "#Tabela de retornos coloridos\n",
    "worksheet.insert_textbox('B8', 'Retorno do fundo - Retorno do benchmarck',options2)\n",
    "table_size = len(df.Ano.unique()) + 4\n",
    "\n",
    "for i in range(len(col_fundos)):\n",
    "    function_retorno(df_concat,i,const,col_fundos).to_excel(writer,sheet_name = 'Sumario',startrow=(8 + table_size*i), startcol=0,index_label='Retorno')\n",
    "    if col_fundos[i] in spread_names:\n",
    "        worksheet.insert_textbox('B'+ str((8 + table_size*i)), 'Spread do Retorno',options2)\n",
    "    else:    \n",
    "        worksheet.insert_textbox('B'+ str((8 + table_size*i)), 'Retorno',options3)\n",
    "    \n",
    "#Graficos\n",
    "\n",
    "worksheet.insert_image('R'+ str((8+ len(df_univar)+10)),'PairplotRegressaoLin.'+nome_da_base+'.png')\n",
    "worksheet.insert_image('U'+ str((8+ len(df_univar)+10)),'Retorno_density_distribution'+nome_da_base+'.png')\n",
    "worksheet.insert_image('X'+ str((8+ len(df_univar)+10)) ,'CorrelationMatrix'+nome_da_base+'.png')#,{'x_scale': 2, 'y_scale': 2})    \n",
    "\n",
    "worksheet2 = workbook.add_worksheet('Correlacoes')\n",
    "writer.sheets['Correlacoes'] = worksheet2\n",
    "\n",
    "for i in range(len(df_sub.columns[3:])):\n",
    "    for j in range(i+1,len(df_sub.columns[3:])):    \n",
    "        worksheet2.insert_image('A'+ str((i+j)*20 - 19),'CorrelacaoTemporal_'+nome_da_base+df_sub.columns[3:][i]+df_sub.columns[3:][j]+'.png')\n",
    "        worksheet2.insert_image('K'+ str((i+j)*20 - 19),'HistogramaCorrelações_'+nome_da_base+df_sub.columns[3:][i]+df_sub.columns[3:][j]+'.png')\n",
    "\n",
    "worksheet3 = workbook.add_worksheet('Volatilidade')\n",
    "writer.sheets['Volatilidade'] = worksheet3\n",
    "\n",
    "for i in range(len(df_sub.columns[3:])):\n",
    "    worksheet3.insert_image('A'+ str(i*20+1),'VolatilidadeTemporal'+nome_da_base+df_sub.columns[3:][i]+'.png')\n",
    "    worksheet3.insert_image('K'+ str(i*20+1),'HistogramaVolatilidade'+nome_da_base+df_sub.columns[3:][i]+'.png')    \n",
    "        \n",
    "\n",
    "#Tabelas com os resultados\n",
    "df_univar.to_excel(writer, sheet_name='Sumario',float_format=\"%.2f\",startrow=8,startcol = 17)\n",
    "df_bivar.to_excel(writer, sheet_name='Sumario',float_format=\"%.2f\",startcol=17,startrow = (8+ len(df_univar)+2))\n",
    "\n",
    "#Formata tamanho da coluna\n",
    "writer.sheets['Sumario'].set_column(17, 30, 25)\n",
    "writer.sheets['Sumario'].set_column(0, 0, 15)\n",
    "writer.sheets['Sumario'].set_column(13, 14, 15)\n",
    "\n",
    "df_sub.to_excel(writer,sheet_name = 'UnstackRetornosPercentuais')\n",
    "df.to_excel(writer, sheet_name='StackRetornos1')\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descritivas mensais\n",
    "\n",
    "#df[['Retorno','MesAno','Product']].groupby(['MesAno','Product']).describe().unstack()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "interpreter": {
   "hash": "a00aeec2289cc99a0231b58f96b56a331b4325a429a696208fafbc585e08b4fc"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
